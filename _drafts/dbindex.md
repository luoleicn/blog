# 机器学习方法在建立数据库索引方面的尝试

这篇paper《The Case for Learned Index Structures》是google brain的一个工作，所以网络上流传的也比较广，这两天看了，是比较新颖的一个话题。如作者所说，目前的工作尚不能去取代传统的数据库索引方式，但是用机器学习的方法来建立索引确实给这个研究了几十年的经典问题指出了一个新的研究方向。

### 理论可行性

B-tree可以理解为一个机器学习概念中的“模型”，它的输入是索引的key，返回是索引key对应的数据存放位置。数据库使用B-tree作为索引时，为了减少索引数据量，不是针对每个key都进行了索引，而是把待索引的数据排好序，每n个key值取一个建立索引，这样既可以减少索引数据量，而且搜索索引时实际要找的值位置与搜到的结果之间不会偏离太远，这样B-tree模型与机器学习中的回归树模型看起来就很相似了，两者都是尽力拟合数据，但还是可能会有一定的误差范围，两者的类比如下图：

![image](http://www.luolei.info/source/images/index1.jpg)

同时在大量的数据更新或插入后，B-tree需要进行re-balance操作也可以类比于机器学习模型的re-train概念。

传统的基于B-tree的索引建立方式，算法上考虑的是最差情况的效率可以保证O(logN)，而忽略了实际数据的分布形式，举个极端的例子，需要建立索引的数据是连续的自然数，那么按照这个数据规律去搜索数据可以达到O(1)的效果，要好于O(logN)的效果。机器学习的方法在fit数据分布上相比于B-tree有独特的优势，从这个角度讲，机器学习方法是有建立更好的索引效率的理论可能性的。


此外，CPU的摩尔定律已经失效，而GPU的效率还在持续提升，机器学习方法的模型可以借助于GPU的强大计算能力和发展前景，进一步提升索引效率。

### 机器学习模型-1

针对2亿条web-server日志建立索引，使用的模型是用tensorflow训练的呃有两层隐含层（每层32个节点）全联接的神经网络模型，激活函数使用ReLU，时间戳作为输入，实际数据位置作为输出。对比结果是B-tree数据查找需要300ns，而神经网络耗时8000ns。机器学习模型落败，分析原因如下：

+ tensorflow结合python的前端，不是为小模型快速查询使用的，可以使用C++代码读取tensorflow的模型文件，更快的启动和运算
+ 针对每个样本索引数据，B-tree都是一个简单有效的数据查找方式，而针对机器学习的模型，单个模型的目标是拟合全部的数据，使得平均的误差尽可能小，但是针对局部数据的特性，单个机器学习模型无法照顾到，通过模型定位到大致位置，在确定精确位置时候可能会比较慢（文中称为“最后一公里”问题）
+ B-tree因为不是对所有数据都进行了索引，所以B-tree找到的位置是有误差范围的，但是这种误差范围是有上届的。但是上面训练的模型是无法保证单条数据的误差的界的。
+ B-tree模型对cpu非常友好，可以充分使用cpu的cache，来提升计算速度


### 机器学习模型-2

上面的问题分析发现“最后一公里”问题是性能影响的瓶颈，上亿条的数据使用一个模型来fit会比较困难，所以提出使用一个层次化的专家模型来解决这个问题：



![image](http://www.luolei.info/source/images/index2.jpg)

定义模型为\\(f(x)\\)，\\(x\\)为索引值，\\(y \in [0, N)\\)表示数据位置，\\(M_l\\)表示stage \\(l\\)层的模型，\\(f_l^{(k)}(x)\\)表示stage \\(l\\)层的第k哥模型。

定义目标损失函数为：

$$ L_0 = \sum_{(x,y)} (f_0(x) - y )^2 $$

$$ L_l = \sum_{(x,y)}(f_l^{\lfloor M_l f_{l-1}(x)/N \rfloor}(x) - y)^2 $$

这个模型解决了单模型表达能力的限制问题，同时也像B-tree一样，具备了把数据分段的能力。

基于stage这种特性，可以设置混合模型来更好的对数据建模，第一层需要比较复杂的表达能力，更适合选择神经网络来建模，下面的层使用线性回归来避免过长的计算时间，为了彻底根治“最后一公里”的问题，如果最底层模型的误差的界比较大，就再用B-tree来控制误差范围，具体模型训练算法如下：

![image](http://www.luolei.info/source/images/index3.jpg)


实验结果如下图：

![image](http://www.luolei.info/source/images/index4.jpg)


### 个人感受

+ 虽然作者在论文里给出了几组不同数据源的对比结果，但个人认为作者的模型需要基于数据去作出了复杂的调参过程才能取得看起来比较好的效果，而作者虽然举出了B-tree不够优的例子，但是B-tree的O(logN)的可靠性非常强，对于完全不同的领域对用户来说都是有保障的。
+ 虽然作者给出了适用于插入和更新的索引合并方式，我认为这个模型可能更加适用于读多写少甚至不写的场景，精心调教的模型可以发挥更长久的作用。
+ 这是机器学习在计算机科学传统领域作出的非常有意义的尝试，一些传统领域上，解决问题的思路相对可能已经固定，新的思路很可能会带来性能的改进，这确实是一股清风。

### Ref
https://arxiv.org/abs/1712.01208